# BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding 분석

## 분석

- [BERT란 무엇인가?](https://github.com/wjsrlahrlco1998/TIL/blob/master/BERT/BERT.md)

---

## [Reference]

- [Youtube - 김유빈 : BERT 논문 리뷰](https://www.youtube.com/watch?v=moCNw4j2Fkw)
- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805v2.pdf)