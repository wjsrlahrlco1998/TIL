# 자연어에서 벡터가 의미를 담는 방법



## 1. 임베딩을 만드는 3가지 방법



### 1) Bag of Words

- 단어의 순서는 고려하지 않고 **단어의 빈도 수**와 **등장 여부**만을 고려하여 임베딩하는 기법

- 많이 쓰인 단어가 주제와 더 강한 관련을 맺는다는 전제
- **정보 검색**에 아직도 많이 활용되는 방법
- 통계적 기법으로 **TF-IDF** 방식을 사용한다.



#### (1) TF-IDF(Term Frequency-Inverse Document Frequency)

- TF : 어떤 단어가 특정 문서에 많이 쓰였는지 빈도를 나타낸다.
- DF : 특정 단어가 나타난 문서의 수를 나타낸다.

(TF는 같은 단어라도 문서마다 다른 값을 가지고, DF는 문서가 달라지더라도 단어가 같다면 동일한 값을 가진다)

- IDF : 전체 문서의 수(N)을 해당 단어의 DF로 나눈 뒤 로그를 취한 값으로, **값이 클수록 특이한 단어**라는 의미이다. (이 값은 단어의 주제 예측 능력과 직결된다.) -> 어떤 단어의 주제 예측 능력이 강할 수록 가중치가 커지고 그 반대의 경우 작아진다.



#### (2) Deep Averaging Network

- Bag of Words 가정의 뉴럴 네트워크 버전
- Bag of Words와 마찬가지로 단어의 순서를 고려하지 않는다.